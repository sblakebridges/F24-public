{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOaZF900aZbrWwWfH8H8k0V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sblakebridges/F24-public/blob/main/Reinforcement_Learning_Trading_Strategy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yw98sxA_Mmp",
        "outputId": "684c4fea-9b48-4e62-ebff-02394f9e08a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ta in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ta) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from ta) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.11/dist-packages (0.23.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.1.24)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.14.0)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.11/dist-packages (from tensorflow-addons) (2.13.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: stable-baselines3 in /usr/local/lib/python3.11/dist-packages (2.5.0)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: gym-anytrading in /usr/local/lib/python3.11/dist-packages (2.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (1.0.0)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.5.1+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (3.1.1)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3) (0.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3) (3.0.2)\n",
            "Collecting shimmy\n",
            "  Downloading Shimmy-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: stable-baselines3 in /usr/local/lib/python3.11/dist-packages (2.5.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from shimmy) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.5.1+cu124)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3) (3.0.2)\n",
            "Downloading Shimmy-2.0.0-py3-none-any.whl (30 kB)\n",
            "Installing collected packages: shimmy\n",
            "Successfully installed shimmy-2.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install ta\n",
        "!pip install --upgrade tensorflow keras tensorflow-addons\n",
        "!pip install stable-baselines3 gym gym-anytrading numpy pandas matplotlib\n",
        "!pip install --upgrade shimmy gymnasium stable-baselines3\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Define the stock ticker and timeframe\n",
        "ticker = \"AAPL\"  # Change this to any stock symbol\n",
        "start_date = \"2020-01-01\"\n",
        "end_date = \"2024-01-01\"\n",
        "\n",
        "# Download historical stock data\n",
        "df = yf.download(ticker, start=start_date, end=end_date, interval=\"1d\")\n",
        "\n",
        "# Ensure data is sorted in ascending order\n",
        "df.sort_index(inplace=True)\n",
        "\n",
        "# Feature Engineering (Manual Calculation)\n",
        "\n",
        "# Simple Moving Averages (SMA)\n",
        "df['SMA_10'] = df['Close'].rolling(window=10).mean()\n",
        "df['SMA_50'] = df['Close'].rolling(window=50).mean()\n",
        "\n",
        "# Relative Strength Index (RSI) Calculation\n",
        "delta = df['Close'].diff()\n",
        "gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
        "loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
        "rs = gain / loss\n",
        "df['RSI'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "# Moving Average Convergence Divergence (MACD)\n",
        "short_ema = df['Close'].ewm(span=12, adjust=False).mean()  # 12-day EMA\n",
        "long_ema = df['Close'].ewm(span=26, adjust=False).mean()   # 26-day EMA\n",
        "df['MACD'] = short_ema - long_ema\n",
        "df['MACD_signal'] = df['MACD'].ewm(span=9, adjust=False).mean()  # Signal line\n",
        "\n",
        "# Bollinger Bands (20-day moving average ± 2 standard deviations)\n",
        "df['Middle_BB'] = df['Close'].rolling(window=20).mean()\n",
        "df['Rolling_Std'] = df['Close'].rolling(window=20).std()  # Ensure this is a Series\n",
        "df['Upper_BB'] = df['Middle_BB'] + (df['Rolling_Std'] * 2)\n",
        "df['Lower_BB'] = df['Middle_BB'] - (df['Rolling_Std'] * 2)\n",
        "\n",
        "# Drop the Rolling_Std column after calculation\n",
        "df.drop(columns=['Rolling_Std'], inplace=True)\n",
        "\n",
        "# 🔹 NEW FEATURES 🔹\n",
        "\n",
        "# Daily Returns (Momentum Indicator)\n",
        "df['Daily_Returns'] = df['Close'].pct_change()\n",
        "\n",
        "# Cumulative Returns (Long-Term Trend Indicator)\n",
        "df['Cumulative_Returns'] = (df['Close'] / df['Close'].iloc[0]) - 1\n",
        "\n",
        "# Volatility (Rolling Standard Deviation)\n",
        "df['Volatility_10'] = df['Close'].rolling(window=10).std()\n",
        "\n",
        "# Trading Volume (Market Strength Indicator)\n",
        "df['Trading_Volume'] = df['Volume']\n",
        "\n",
        "# Target Variable: Predict if price goes up (1) or down (0) the next day\n",
        "df['Target'] = np.where(df['Close'].shift(-1) > df['Close'], 1, 0)\n",
        "\n",
        "# Drop NaN values caused by indicator calculations\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(df.head())\n",
        "\n",
        "# Save to CSV (Optional: For easier data analysis)\n",
        "df.to_csv(\"stock_data_with_features.csv\", index=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_zSIqOk_R1m",
        "outputId": "bfec46d3-402c-4f49-837d-0f5553bb5d95"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Price           Close       High        Low       Open     Volume     SMA_10  \\\n",
            "Ticker           AAPL       AAPL       AAPL       AAPL       AAPL              \n",
            "Date                                                                           \n",
            "2020-03-13  67.531662  68.005409  61.453155  64.353933  370732000  68.655523   \n",
            "2020-03-16  58.843918  62.942410  58.307006  58.780750  322423600  67.280451   \n",
            "2020-03-17  61.431286  62.585275  57.918287  60.131524  324056000  66.394670   \n",
            "2020-03-18  59.927460  60.736470  57.607326  58.251135  300233600  65.032473   \n",
            "2020-03-19  59.468288  61.426431  58.941096  60.102377  271857200  63.862931   \n",
            "\n",
            "Price          SMA_50        RSI      MACD MACD_signal  Middle_BB   Upper_BB  \\\n",
            "Ticker                                                                         \n",
            "Date                                                                           \n",
            "2020-03-13  74.204477  45.068568 -2.659556   -2.035598  71.094094  81.108389   \n",
            "2020-03-16  73.925435  40.052918 -3.223398   -2.273158  70.089026  80.796445   \n",
            "2020-03-17  73.712294  41.593072 -3.422020   -2.502930  69.285605  80.062874   \n",
            "2020-03-18  73.457589  43.998929 -3.658602   -2.734065  68.350871  78.960099   \n",
            "2020-03-19  73.200536  43.661296 -3.838894   -2.955031  67.433507  77.766167   \n",
            "\n",
            "Price        Lower_BB Daily_Returns Cumulative_Returns Volatility_10  \\\n",
            "Ticker                                                                 \n",
            "Date                                                                   \n",
            "2020-03-13  61.079798      0.119808          -0.072316      3.961486   \n",
            "2020-03-16  59.381608     -0.128647          -0.191660      4.750241   \n",
            "2020-03-17  58.508336      0.043970          -0.156117      4.948601   \n",
            "2020-03-18  57.741643     -0.024480          -0.176775      4.624527   \n",
            "2020-03-19  57.100847     -0.007662          -0.183083      4.373736   \n",
            "\n",
            "Price      Trading_Volume Target  \n",
            "Ticker                            \n",
            "Date                              \n",
            "2020-03-13      370732000      0  \n",
            "2020-03-16      322423600      1  \n",
            "2020-03-17      324056000      0  \n",
            "2020-03-18      300233600      0  \n",
            "2020-03-19      271857200      0  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# Define the updated feature list\n",
        "features = [\n",
        "    'SMA_10', 'SMA_50', 'RSI', 'MACD', 'MACD_signal', 'Upper_BB', 'Middle_BB', 'Lower_BB',\n",
        "    'Daily_Returns', 'Cumulative_Returns', 'Volatility_10', 'Trading_Volume'\n",
        "]\n",
        "\n",
        "# Normalize the features using MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(df[features])\n",
        "\n",
        "# Define sequence length (how many past days to look at)\n",
        "sequence_length = 10\n",
        "\n",
        "X_lstm, y_lstm = [], []\n",
        "\n",
        "# Create sequences for LSTM\n",
        "for i in range(sequence_length, len(X_scaled)):\n",
        "    X_lstm.append(X_scaled[i-sequence_length:i])  # Past 10 days of data\n",
        "    y_lstm.append(df['Target'].iloc[i])  # Target for the next day\n",
        "\n",
        "X_lstm, y_lstm = np.array(X_lstm), np.array(y_lstm)\n",
        "\n",
        "# Split into training (80%) and testing (20%) sets\n",
        "split = int(0.8 * len(X_lstm))\n",
        "X_train, X_test = X_lstm[:split], X_lstm[split:]\n",
        "y_train, y_test = y_lstm[:split], y_lstm[split:]\n",
        "\n",
        "# Print dataset shape\n",
        "print(f\"Updated Training Set Shape: {X_train.shape}\")\n",
        "print(f\"Updated Testing Set Shape: {X_test.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cl0Pcp50Bukz",
        "outputId": "0281c33c-81fa-444f-a8ad-36b9db6f7701"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated Training Set Shape: (757, 10, 12)\n",
            "Updated Testing Set Shape: (190, 10, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Build LSTM Model\n",
        "model = Sequential([\n",
        "    LSTM(units=128, return_sequences=True, input_shape=(sequence_length, len(features))),  # Increased units\n",
        "    Dropout(0.2),\n",
        "    LSTM(units=128),\n",
        "    Dropout(0.2),\n",
        "    Dense(units=1, activation='sigmoid')  # Binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwlu53kICpJg",
        "outputId": "20d55e69-46ce-4789-b140-14b74a34c708"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 60ms/step - accuracy: 0.4595 - loss: 0.7051 - val_accuracy: 0.5368 - val_loss: 0.6917\n",
            "Epoch 2/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5307 - loss: 0.6934 - val_accuracy: 0.4579 - val_loss: 0.6940\n",
            "Epoch 3/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5252 - loss: 0.6917 - val_accuracy: 0.5368 - val_loss: 0.6922\n",
            "Epoch 4/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5223 - loss: 0.6911 - val_accuracy: 0.5263 - val_loss: 0.6931\n",
            "Epoch 5/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5129 - loss: 0.6898 - val_accuracy: 0.4316 - val_loss: 0.6951\n",
            "Epoch 6/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5597 - loss: 0.6864 - val_accuracy: 0.4632 - val_loss: 0.7019\n",
            "Epoch 7/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5632 - loss: 0.6858 - val_accuracy: 0.4632 - val_loss: 0.6977\n",
            "Epoch 8/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5348 - loss: 0.6916 - val_accuracy: 0.5526 - val_loss: 0.6923\n",
            "Epoch 9/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.5600 - loss: 0.6831 - val_accuracy: 0.4632 - val_loss: 0.7093\n",
            "Epoch 10/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5295 - loss: 0.6850 - val_accuracy: 0.4684 - val_loss: 0.6959\n",
            "Epoch 11/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.5439 - loss: 0.6901 - val_accuracy: 0.5421 - val_loss: 0.6909\n",
            "Epoch 12/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.4994 - loss: 0.6923 - val_accuracy: 0.4579 - val_loss: 0.6965\n",
            "Epoch 13/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5473 - loss: 0.6865 - val_accuracy: 0.5368 - val_loss: 0.6916\n",
            "Epoch 14/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5206 - loss: 0.6908 - val_accuracy: 0.5158 - val_loss: 0.6912\n",
            "Epoch 15/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5679 - loss: 0.6856 - val_accuracy: 0.5579 - val_loss: 0.6923\n",
            "Epoch 16/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5254 - loss: 0.6895 - val_accuracy: 0.5316 - val_loss: 0.6921\n",
            "Epoch 17/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5341 - loss: 0.6884 - val_accuracy: 0.4632 - val_loss: 0.6988\n",
            "Epoch 18/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5257 - loss: 0.6912 - val_accuracy: 0.5211 - val_loss: 0.6906\n",
            "Epoch 19/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5513 - loss: 0.6838 - val_accuracy: 0.5105 - val_loss: 0.6941\n",
            "Epoch 20/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.5810 - loss: 0.6750 - val_accuracy: 0.4526 - val_loss: 0.7014\n",
            "Epoch 21/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.5353 - loss: 0.6869 - val_accuracy: 0.5316 - val_loss: 0.6929\n",
            "Epoch 22/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5783 - loss: 0.6838 - val_accuracy: 0.5316 - val_loss: 0.6908\n",
            "Epoch 23/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5560 - loss: 0.6860 - val_accuracy: 0.5263 - val_loss: 0.6900\n",
            "Epoch 24/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5454 - loss: 0.6864 - val_accuracy: 0.5158 - val_loss: 0.6946\n",
            "Epoch 25/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5185 - loss: 0.6845 - val_accuracy: 0.4947 - val_loss: 0.6917\n",
            "Epoch 26/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5498 - loss: 0.6831 - val_accuracy: 0.5105 - val_loss: 0.6945\n",
            "Epoch 27/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5070 - loss: 0.6898 - val_accuracy: 0.5000 - val_loss: 0.6915\n",
            "Epoch 28/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.5377 - loss: 0.6906 - val_accuracy: 0.5158 - val_loss: 0.6953\n",
            "Epoch 29/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.5403 - loss: 0.6917 - val_accuracy: 0.5421 - val_loss: 0.6916\n",
            "Epoch 30/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.5191 - loss: 0.6897 - val_accuracy: 0.5368 - val_loss: 0.6907\n",
            "Epoch 31/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5444 - loss: 0.6873 - val_accuracy: 0.5211 - val_loss: 0.6890\n",
            "Epoch 32/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5907 - loss: 0.6782 - val_accuracy: 0.4684 - val_loss: 0.7031\n",
            "Epoch 33/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5322 - loss: 0.6860 - val_accuracy: 0.5316 - val_loss: 0.6938\n",
            "Epoch 34/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5346 - loss: 0.6833 - val_accuracy: 0.4895 - val_loss: 0.6958\n",
            "Epoch 35/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5760 - loss: 0.6789 - val_accuracy: 0.4789 - val_loss: 0.7005\n",
            "Epoch 36/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5161 - loss: 0.6879 - val_accuracy: 0.5316 - val_loss: 0.6886\n",
            "Epoch 37/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5384 - loss: 0.6865 - val_accuracy: 0.5263 - val_loss: 0.6925\n",
            "Epoch 38/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5622 - loss: 0.6797 - val_accuracy: 0.5263 - val_loss: 0.6931\n",
            "Epoch 39/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.5743 - loss: 0.6767 - val_accuracy: 0.5105 - val_loss: 0.6939\n",
            "Epoch 40/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.5589 - loss: 0.6834 - val_accuracy: 0.4947 - val_loss: 0.6956\n",
            "Epoch 41/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5564 - loss: 0.6812 - val_accuracy: 0.5053 - val_loss: 0.6922\n",
            "Epoch 42/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5326 - loss: 0.6869 - val_accuracy: 0.5368 - val_loss: 0.6895\n",
            "Epoch 43/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5481 - loss: 0.6848 - val_accuracy: 0.5000 - val_loss: 0.6911\n",
            "Epoch 44/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5611 - loss: 0.6809 - val_accuracy: 0.5316 - val_loss: 0.6910\n",
            "Epoch 45/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5516 - loss: 0.6822 - val_accuracy: 0.5000 - val_loss: 0.7005\n",
            "Epoch 46/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5489 - loss: 0.6846 - val_accuracy: 0.5053 - val_loss: 0.6892\n",
            "Epoch 47/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5033 - loss: 0.6902 - val_accuracy: 0.5211 - val_loss: 0.6898\n",
            "Epoch 48/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.5511 - loss: 0.6826 - val_accuracy: 0.5158 - val_loss: 0.6895\n",
            "Epoch 49/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.5742 - loss: 0.6828 - val_accuracy: 0.5211 - val_loss: 0.6891\n",
            "Epoch 50/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5604 - loss: 0.6802 - val_accuracy: 0.5474 - val_loss: 0.6914\n",
            "Epoch 51/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5629 - loss: 0.6817 - val_accuracy: 0.4947 - val_loss: 0.6982\n",
            "Epoch 52/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5700 - loss: 0.6782 - val_accuracy: 0.5053 - val_loss: 0.6955\n",
            "Epoch 53/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5690 - loss: 0.6765 - val_accuracy: 0.5263 - val_loss: 0.6901\n",
            "Epoch 54/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5405 - loss: 0.6836 - val_accuracy: 0.5158 - val_loss: 0.6895\n",
            "Epoch 55/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5808 - loss: 0.6731 - val_accuracy: 0.4789 - val_loss: 0.7037\n",
            "Epoch 56/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5775 - loss: 0.6822 - val_accuracy: 0.5158 - val_loss: 0.6981\n",
            "Epoch 57/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.5539 - loss: 0.6776 - val_accuracy: 0.5105 - val_loss: 0.6961\n",
            "Epoch 58/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.5577 - loss: 0.6830 - val_accuracy: 0.5000 - val_loss: 0.6926\n",
            "Epoch 59/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5502 - loss: 0.6800 - val_accuracy: 0.5474 - val_loss: 0.6955\n",
            "Epoch 60/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5604 - loss: 0.6802 - val_accuracy: 0.5263 - val_loss: 0.6910\n",
            "Epoch 61/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5626 - loss: 0.6802 - val_accuracy: 0.4895 - val_loss: 0.6940\n",
            "Epoch 62/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5625 - loss: 0.6830 - val_accuracy: 0.5368 - val_loss: 0.6877\n",
            "Epoch 63/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5571 - loss: 0.6801 - val_accuracy: 0.5316 - val_loss: 0.6939\n",
            "Epoch 64/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5619 - loss: 0.6806 - val_accuracy: 0.5000 - val_loss: 0.6885\n",
            "Epoch 65/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5628 - loss: 0.6777 - val_accuracy: 0.5211 - val_loss: 0.6914\n",
            "Epoch 66/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5681 - loss: 0.6676 - val_accuracy: 0.5474 - val_loss: 0.6951\n",
            "Epoch 67/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5356 - loss: 0.6848 - val_accuracy: 0.5000 - val_loss: 0.6891\n",
            "Epoch 68/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.6108 - loss: 0.6700 - val_accuracy: 0.4842 - val_loss: 0.7030\n",
            "Epoch 69/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.5661 - loss: 0.6744 - val_accuracy: 0.5053 - val_loss: 0.6933\n",
            "Epoch 70/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5846 - loss: 0.6743 - val_accuracy: 0.5263 - val_loss: 0.6874\n",
            "Epoch 71/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5703 - loss: 0.6707 - val_accuracy: 0.5368 - val_loss: 0.6901\n",
            "Epoch 72/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5771 - loss: 0.6688 - val_accuracy: 0.5368 - val_loss: 0.6964\n",
            "Epoch 73/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5533 - loss: 0.6779 - val_accuracy: 0.5474 - val_loss: 0.6858\n",
            "Epoch 74/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5348 - loss: 0.6792 - val_accuracy: 0.5632 - val_loss: 0.6872\n",
            "Epoch 75/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5211 - loss: 0.6841 - val_accuracy: 0.4737 - val_loss: 0.6920\n",
            "Epoch 76/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5914 - loss: 0.6754 - val_accuracy: 0.5105 - val_loss: 0.6985\n",
            "Epoch 77/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5721 - loss: 0.6738 - val_accuracy: 0.5368 - val_loss: 0.6885\n",
            "Epoch 78/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.5728 - loss: 0.6746 - val_accuracy: 0.5316 - val_loss: 0.6932\n",
            "Epoch 79/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.5533 - loss: 0.6772 - val_accuracy: 0.5316 - val_loss: 0.6869\n",
            "Epoch 80/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5610 - loss: 0.6769 - val_accuracy: 0.5474 - val_loss: 0.6861\n",
            "Epoch 81/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5567 - loss: 0.6710 - val_accuracy: 0.5211 - val_loss: 0.6902\n",
            "Epoch 82/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5825 - loss: 0.6586 - val_accuracy: 0.5263 - val_loss: 0.6937\n",
            "Epoch 83/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5984 - loss: 0.6601 - val_accuracy: 0.4789 - val_loss: 0.7119\n",
            "Epoch 84/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5810 - loss: 0.6674 - val_accuracy: 0.5158 - val_loss: 0.6947\n",
            "Epoch 85/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.6117 - loss: 0.6645 - val_accuracy: 0.5263 - val_loss: 0.6885\n",
            "Epoch 86/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5510 - loss: 0.6692 - val_accuracy: 0.5211 - val_loss: 0.6965\n",
            "Epoch 87/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5689 - loss: 0.6653 - val_accuracy: 0.5368 - val_loss: 0.6931\n",
            "Epoch 88/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.5894 - loss: 0.6650 - val_accuracy: 0.5263 - val_loss: 0.6931\n",
            "Epoch 89/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.5902 - loss: 0.6676 - val_accuracy: 0.5211 - val_loss: 0.6873\n",
            "Epoch 90/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5370 - loss: 0.6721 - val_accuracy: 0.5158 - val_loss: 0.6970\n",
            "Epoch 91/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5931 - loss: 0.6673 - val_accuracy: 0.4789 - val_loss: 0.7075\n",
            "Epoch 92/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.5734 - loss: 0.6756 - val_accuracy: 0.5421 - val_loss: 0.6864\n",
            "Epoch 93/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.5901 - loss: 0.6621 - val_accuracy: 0.5474 - val_loss: 0.6906\n",
            "Epoch 94/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5963 - loss: 0.6538 - val_accuracy: 0.5158 - val_loss: 0.6893\n",
            "Epoch 95/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.6088 - loss: 0.6489 - val_accuracy: 0.5158 - val_loss: 0.6931\n",
            "Epoch 96/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5420 - loss: 0.6799 - val_accuracy: 0.5316 - val_loss: 0.6871\n",
            "Epoch 97/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.5710 - loss: 0.6555 - val_accuracy: 0.5474 - val_loss: 0.6904\n",
            "Epoch 98/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.6061 - loss: 0.6662 - val_accuracy: 0.5000 - val_loss: 0.7044\n",
            "Epoch 99/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.6195 - loss: 0.6634 - val_accuracy: 0.5211 - val_loss: 0.6904\n",
            "Epoch 100/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5548 - loss: 0.6712 - val_accuracy: 0.5105 - val_loss: 0.6895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Updated LSTM Test Accuracy: {test_acc:.2f}\")\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_lstm = (model.predict(X_test) > 0.5).astype(int)\n",
        "\n",
        "# Classification Report\n",
        "from sklearn.metrics import classification_report\n",
        "print(\"\\nUpdated Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_lstm))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vTkXaOrC7nk",
        "outputId": "3ef9d637-3f13-479f-c2cd-c727e09a8125"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4885 - loss: 0.6968\n",
            "Updated LSTM Test Accuracy: 0.51\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step\n",
            "\n",
            "Updated Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.45      0.46        88\n",
            "           1       0.54      0.56      0.55       102\n",
            "\n",
            "    accuracy                           0.51       190\n",
            "   macro avg       0.51      0.51      0.51       190\n",
            "weighted avg       0.51      0.51      0.51       190\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# Define the updated feature list\n",
        "features = [\n",
        "    'SMA_10', 'SMA_50', 'RSI', 'MACD', 'MACD_signal', 'Upper_BB', 'Middle_BB', 'Lower_BB',\n",
        "    'Daily_Returns', 'Cumulative_Returns', 'Volatility_10', 'Trading_Volume'\n",
        "]\n",
        "\n",
        "# Normalize the features using MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(df[features])\n",
        "\n",
        "# Define sequence length (how many past days to look at)\n",
        "sequence_length = 10\n",
        "\n",
        "X_lstm, y_lstm = [], []\n",
        "\n",
        "# Create sequences for CNN-LSTM\n",
        "for i in range(sequence_length, len(X_scaled)):\n",
        "    X_lstm.append(X_scaled[i-sequence_length:i])  # Past 10 days of data\n",
        "    y_lstm.append(df['Target'].iloc[i])  # Target for the next day\n",
        "\n",
        "X_lstm, y_lstm = np.array(X_lstm), np.array(y_lstm)\n",
        "\n",
        "# Reshape data for CNN (adding 1 extra channel for CNN input)\n",
        "X_lstm = X_lstm.reshape((X_lstm.shape[0], X_lstm.shape[1], X_lstm.shape[2], 1))  # (samples, timesteps, features, channels)\n",
        "\n",
        "# Split into training/testing sets\n",
        "split = int(0.8 * len(X_lstm))\n",
        "X_train, X_test = X_lstm[:split], X_lstm[split:]\n",
        "y_train, y_test = y_lstm[:split], y_lstm[split:]\n",
        "\n",
        "# Print dataset shape\n",
        "print(f\"Updated Training Set Shape: {X_train.shape}\")\n",
        "print(f\"Updated Testing Set Shape: {X_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjWgTA1mKzuY",
        "outputId": "1fddacc1-89f1-47f3-84b6-6fa2d2a82993"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated Training Set Shape: (757, 10, 12, 1)\n",
            "Updated Testing Set Shape: (190, 10, 12, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow keras tensorflow-addons\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, LSTM, Dense, Dropout, TimeDistributed, Input, Multiply, Reshape\n",
        "\n",
        "# Custom Attention Layer (Final Fix)\n",
        "class AttentionLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(AttentionLayer, self).__init__()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(name=\"attention_weight\", shape=(input_shape[-1], 1), initializer=\"normal\", trainable=True)\n",
        "        self.b = self.add_weight(name=\"attention_bias\", shape=(1,), initializer=\"zeros\", trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        attention_scores = tf.keras.backend.dot(inputs, self.W) + self.b  # Compute scores\n",
        "        attention_weights = tf.keras.backend.softmax(attention_scores, axis=1)  # Apply softmax\n",
        "        context_vector = Multiply()([inputs, attention_weights])  # Apply attention weights\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1, keepdims=False)  # Fix: Remove extra dim\n",
        "        return context_vector  # Now shape is (None, 100) instead of (None, 1, 1)\n",
        "\n",
        "# Build CNN-LSTM with Fixed Attention Output\n",
        "input_layer = Input(shape=(10, 12, 1))  # (time steps, features, channels)\n",
        "\n",
        "# CNN Layers\n",
        "cnn_layer = TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'))(input_layer)\n",
        "cnn_layer = TimeDistributed(MaxPooling1D(pool_size=2))(cnn_layer)\n",
        "cnn_layer = TimeDistributed(Flatten())(cnn_layer)\n",
        "\n",
        "# LSTM Layer (return_sequences=True for Attention)\n",
        "lstm_layer = LSTM(units=100, return_sequences=True)(cnn_layer)\n",
        "dropout_layer = Dropout(0.2)(lstm_layer)\n",
        "\n",
        "# Attention Layer (Fixed Output Shape)\n",
        "attention_output = AttentionLayer()(dropout_layer)\n",
        "\n",
        "# Fully Connected Layer\n",
        "dense_layer = Dense(units=50, activation='relu')(attention_output)\n",
        "dropout_layer2 = Dropout(0.2)(dense_layer)\n",
        "\n",
        "# Output Layer (Binary Classification)\n",
        "output_layer = Dense(units=1, activation='sigmoid')(dropout_layer2)  # Final shape (None, 1)\n",
        "\n",
        "# Define Model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Compile the Model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print Model Summary\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fSYEF92QK5t8",
        "outputId": "d6aa7a84-a562-48ef-ac32-0d07611edf43"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.11/dist-packages (0.23.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.1.24)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.14.0)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.11/dist-packages (from tensorflow-addons) (2.13.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_7 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_15                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_16                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_17                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m320\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m100\u001b[0m)             │         \u001b[38;5;34m168,400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m100\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ attention_layer_4 (\u001b[38;5;33mAttentionLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │             \u001b[38;5;34m101\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │           \u001b[38;5;34m5,050\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m51\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_15                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_16                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_17                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">168,400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ attention_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,050</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m173,858\u001b[0m (679.13 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">173,858</span> (679.13 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m173,858\u001b[0m (679.13 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">173,858</span> (679.13 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the CNN-LSTM with Fixed Attention Model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2CJeVQkK9M9",
        "outputId": "f6610131-dc80-4888-c648-1fa8e1a572f8"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 77ms/step - accuracy: 0.5013 - loss: 0.6959 - val_accuracy: 0.5368 - val_loss: 0.6905\n",
            "Epoch 2/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.5308 - loss: 0.6914 - val_accuracy: 0.5368 - val_loss: 0.6902\n",
            "Epoch 3/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5155 - loss: 0.6919 - val_accuracy: 0.5368 - val_loss: 0.6916\n",
            "Epoch 4/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5265 - loss: 0.6908 - val_accuracy: 0.5368 - val_loss: 0.6913\n",
            "Epoch 5/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5466 - loss: 0.6894 - val_accuracy: 0.4526 - val_loss: 0.6937\n",
            "Epoch 6/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.5479 - loss: 0.6897 - val_accuracy: 0.5368 - val_loss: 0.6899\n",
            "Epoch 7/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.5185 - loss: 0.6918 - val_accuracy: 0.5368 - val_loss: 0.6901\n",
            "Epoch 8/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.5275 - loss: 0.6890 - val_accuracy: 0.5579 - val_loss: 0.6911\n",
            "Epoch 9/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5378 - loss: 0.6909 - val_accuracy: 0.5421 - val_loss: 0.6915\n",
            "Epoch 10/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5449 - loss: 0.6867 - val_accuracy: 0.5368 - val_loss: 0.6918\n",
            "Epoch 11/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5439 - loss: 0.6848 - val_accuracy: 0.4632 - val_loss: 0.6969\n",
            "Epoch 12/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5538 - loss: 0.6889 - val_accuracy: 0.5474 - val_loss: 0.6902\n",
            "Epoch 13/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5423 - loss: 0.6886 - val_accuracy: 0.5158 - val_loss: 0.6927\n",
            "Epoch 14/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.5509 - loss: 0.6908 - val_accuracy: 0.5316 - val_loss: 0.6924\n",
            "Epoch 15/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5370 - loss: 0.6843 - val_accuracy: 0.5158 - val_loss: 0.6897\n",
            "Epoch 16/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5660 - loss: 0.6840 - val_accuracy: 0.5474 - val_loss: 0.6881\n",
            "Epoch 17/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.5696 - loss: 0.6847 - val_accuracy: 0.4684 - val_loss: 0.7049\n",
            "Epoch 18/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.5796 - loss: 0.6847 - val_accuracy: 0.5368 - val_loss: 0.6876\n",
            "Epoch 19/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5399 - loss: 0.6826 - val_accuracy: 0.5053 - val_loss: 0.6943\n",
            "Epoch 20/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.5369 - loss: 0.6891 - val_accuracy: 0.4737 - val_loss: 0.6990\n",
            "Epoch 21/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.5456 - loss: 0.6853 - val_accuracy: 0.5368 - val_loss: 0.6913\n",
            "Epoch 22/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5115 - loss: 0.6960 - val_accuracy: 0.5316 - val_loss: 0.6875\n",
            "Epoch 23/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.5155 - loss: 0.6939 - val_accuracy: 0.5053 - val_loss: 0.6925\n",
            "Epoch 24/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.5524 - loss: 0.6867 - val_accuracy: 0.4947 - val_loss: 0.6941\n",
            "Epoch 25/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.5587 - loss: 0.6848 - val_accuracy: 0.5000 - val_loss: 0.6954\n",
            "Epoch 26/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.5432 - loss: 0.6838 - val_accuracy: 0.5474 - val_loss: 0.6919\n",
            "Epoch 27/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.5142 - loss: 0.6912 - val_accuracy: 0.5316 - val_loss: 0.6918\n",
            "Epoch 28/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.5463 - loss: 0.6840 - val_accuracy: 0.4789 - val_loss: 0.6993\n",
            "Epoch 29/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.5828 - loss: 0.6802 - val_accuracy: 0.5053 - val_loss: 0.6944\n",
            "Epoch 30/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.5666 - loss: 0.6869 - val_accuracy: 0.5053 - val_loss: 0.6886\n",
            "Epoch 31/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.5572 - loss: 0.6819 - val_accuracy: 0.5263 - val_loss: 0.6890\n",
            "Epoch 32/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5281 - loss: 0.6972 - val_accuracy: 0.5211 - val_loss: 0.6875\n",
            "Epoch 33/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5621 - loss: 0.6848 - val_accuracy: 0.5158 - val_loss: 0.6927\n",
            "Epoch 34/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5653 - loss: 0.6804 - val_accuracy: 0.5000 - val_loss: 0.6960\n",
            "Epoch 35/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5566 - loss: 0.6846 - val_accuracy: 0.5368 - val_loss: 0.6865\n",
            "Epoch 36/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5500 - loss: 0.6806 - val_accuracy: 0.5158 - val_loss: 0.6932\n",
            "Epoch 37/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.5526 - loss: 0.6817 - val_accuracy: 0.5053 - val_loss: 0.6926\n",
            "Epoch 38/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.5778 - loss: 0.6807 - val_accuracy: 0.5053 - val_loss: 0.6926\n",
            "Epoch 39/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.5561 - loss: 0.6879 - val_accuracy: 0.5158 - val_loss: 0.6905\n",
            "Epoch 40/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5087 - loss: 0.6934 - val_accuracy: 0.5053 - val_loss: 0.6921\n",
            "Epoch 41/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.5827 - loss: 0.6787 - val_accuracy: 0.5421 - val_loss: 0.6902\n",
            "Epoch 42/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5804 - loss: 0.6762 - val_accuracy: 0.5105 - val_loss: 0.6895\n",
            "Epoch 43/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5543 - loss: 0.6855 - val_accuracy: 0.4842 - val_loss: 0.6992\n",
            "Epoch 44/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.5660 - loss: 0.6790 - val_accuracy: 0.5105 - val_loss: 0.6919\n",
            "Epoch 45/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5642 - loss: 0.6766 - val_accuracy: 0.5105 - val_loss: 0.7006\n",
            "Epoch 46/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5978 - loss: 0.6759 - val_accuracy: 0.5421 - val_loss: 0.6916\n",
            "Epoch 47/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.5789 - loss: 0.6843 - val_accuracy: 0.5474 - val_loss: 0.6899\n",
            "Epoch 48/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.5934 - loss: 0.6757 - val_accuracy: 0.5211 - val_loss: 0.6954\n",
            "Epoch 49/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.5815 - loss: 0.6761 - val_accuracy: 0.4947 - val_loss: 0.6995\n",
            "Epoch 50/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5746 - loss: 0.6850 - val_accuracy: 0.5211 - val_loss: 0.6890\n",
            "Epoch 51/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.5764 - loss: 0.6748 - val_accuracy: 0.5263 - val_loss: 0.6931\n",
            "Epoch 52/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.5718 - loss: 0.6733 - val_accuracy: 0.5421 - val_loss: 0.6901\n",
            "Epoch 53/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.5695 - loss: 0.6820 - val_accuracy: 0.5263 - val_loss: 0.6870\n",
            "Epoch 54/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.5360 - loss: 0.6908 - val_accuracy: 0.5053 - val_loss: 0.6943\n",
            "Epoch 55/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5797 - loss: 0.6768 - val_accuracy: 0.5105 - val_loss: 0.6967\n",
            "Epoch 56/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.5645 - loss: 0.6809 - val_accuracy: 0.5316 - val_loss: 0.6926\n",
            "Epoch 57/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.5486 - loss: 0.6781 - val_accuracy: 0.5000 - val_loss: 0.6984\n",
            "Epoch 58/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.6056 - loss: 0.6638 - val_accuracy: 0.5053 - val_loss: 0.6998\n",
            "Epoch 59/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.5690 - loss: 0.6793 - val_accuracy: 0.5211 - val_loss: 0.6928\n",
            "Epoch 60/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5868 - loss: 0.6829 - val_accuracy: 0.5474 - val_loss: 0.7018\n",
            "Epoch 61/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.5571 - loss: 0.6787 - val_accuracy: 0.5421 - val_loss: 0.6912\n",
            "Epoch 62/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5656 - loss: 0.6835 - val_accuracy: 0.5737 - val_loss: 0.6884\n",
            "Epoch 63/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.6090 - loss: 0.6708 - val_accuracy: 0.5105 - val_loss: 0.6977\n",
            "Epoch 64/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5930 - loss: 0.6710 - val_accuracy: 0.5316 - val_loss: 0.6937\n",
            "Epoch 65/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5703 - loss: 0.6723 - val_accuracy: 0.5316 - val_loss: 0.6990\n",
            "Epoch 66/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5826 - loss: 0.6664 - val_accuracy: 0.4789 - val_loss: 0.7027\n",
            "Epoch 67/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.4850 - loss: 0.6961 - val_accuracy: 0.5158 - val_loss: 0.6909\n",
            "Epoch 68/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.5591 - loss: 0.6832 - val_accuracy: 0.5474 - val_loss: 0.6892\n",
            "Epoch 69/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.6083 - loss: 0.6698 - val_accuracy: 0.5105 - val_loss: 0.6943\n",
            "Epoch 70/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.5858 - loss: 0.6712 - val_accuracy: 0.4947 - val_loss: 0.6981\n",
            "Epoch 71/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.5520 - loss: 0.6868 - val_accuracy: 0.5474 - val_loss: 0.6983\n",
            "Epoch 72/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.5338 - loss: 0.6855 - val_accuracy: 0.5263 - val_loss: 0.6905\n",
            "Epoch 73/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.5830 - loss: 0.6718 - val_accuracy: 0.5000 - val_loss: 0.6997\n",
            "Epoch 74/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5647 - loss: 0.6750 - val_accuracy: 0.5789 - val_loss: 0.6843\n",
            "Epoch 75/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.6146 - loss: 0.6719 - val_accuracy: 0.5368 - val_loss: 0.7006\n",
            "Epoch 76/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.5658 - loss: 0.6721 - val_accuracy: 0.5211 - val_loss: 0.6965\n",
            "Epoch 77/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.6085 - loss: 0.6701 - val_accuracy: 0.5211 - val_loss: 0.6897\n",
            "Epoch 78/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.5797 - loss: 0.6730 - val_accuracy: 0.5211 - val_loss: 0.6917\n",
            "Epoch 79/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.5831 - loss: 0.6730 - val_accuracy: 0.5211 - val_loss: 0.6964\n",
            "Epoch 80/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5982 - loss: 0.6716 - val_accuracy: 0.5053 - val_loss: 0.6989\n",
            "Epoch 81/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5937 - loss: 0.6662 - val_accuracy: 0.5263 - val_loss: 0.6887\n",
            "Epoch 82/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.5727 - loss: 0.6728 - val_accuracy: 0.5526 - val_loss: 0.6999\n",
            "Epoch 83/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.6172 - loss: 0.6641 - val_accuracy: 0.5421 - val_loss: 0.6944\n",
            "Epoch 84/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.5874 - loss: 0.6706 - val_accuracy: 0.5421 - val_loss: 0.7063\n",
            "Epoch 85/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.5996 - loss: 0.6592 - val_accuracy: 0.5211 - val_loss: 0.6972\n",
            "Epoch 86/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.5754 - loss: 0.6667 - val_accuracy: 0.5158 - val_loss: 0.6951\n",
            "Epoch 87/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5648 - loss: 0.6687 - val_accuracy: 0.5105 - val_loss: 0.7018\n",
            "Epoch 88/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.5910 - loss: 0.6687 - val_accuracy: 0.5263 - val_loss: 0.7012\n",
            "Epoch 89/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5922 - loss: 0.6648 - val_accuracy: 0.5421 - val_loss: 0.6882\n",
            "Epoch 90/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.5913 - loss: 0.6628 - val_accuracy: 0.5684 - val_loss: 0.6828\n",
            "Epoch 91/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.5772 - loss: 0.6650 - val_accuracy: 0.5211 - val_loss: 0.6922\n",
            "Epoch 92/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5744 - loss: 0.6708 - val_accuracy: 0.5316 - val_loss: 0.6943\n",
            "Epoch 93/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.5662 - loss: 0.6669 - val_accuracy: 0.5368 - val_loss: 0.6962\n",
            "Epoch 94/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5799 - loss: 0.6697 - val_accuracy: 0.5316 - val_loss: 0.6952\n",
            "Epoch 95/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5479 - loss: 0.6817 - val_accuracy: 0.5000 - val_loss: 0.6890\n",
            "Epoch 96/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.5951 - loss: 0.6733 - val_accuracy: 0.5211 - val_loss: 0.7046\n",
            "Epoch 97/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.5856 - loss: 0.6640 - val_accuracy: 0.5421 - val_loss: 0.6869\n",
            "Epoch 98/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5936 - loss: 0.6645 - val_accuracy: 0.5316 - val_loss: 0.7013\n",
            "Epoch 99/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.6139 - loss: 0.6678 - val_accuracy: 0.5158 - val_loss: 0.6995\n",
            "Epoch 100/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5938 - loss: 0.6632 - val_accuracy: 0.5474 - val_loss: 0.6971\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Attention-CNN-LSTM Test Accuracy: {test_acc:.2f}\")\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_attention = (model.predict(X_test) > 0.5).astype(int)\n",
        "\n",
        "# Classification Report\n",
        "from sklearn.metrics import classification_report\n",
        "print(\"\\nAttention-CNN-LSTM Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_attention))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUoP-xeTMvcu",
        "outputId": "f0ea9368-6a46-4172-96de-ba96924927ac"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5639 - loss: 0.6991\n",
            "Attention-CNN-LSTM Test Accuracy: 0.55\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x785f1faa3420> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 461ms/step\n",
            "\n",
            "Attention-CNN-LSTM Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.56      0.53        88\n",
            "           1       0.59      0.54      0.56       102\n",
            "\n",
            "    accuracy                           0.55       190\n",
            "   macro avg       0.55      0.55      0.55       190\n",
            "weighted avg       0.55      0.55      0.55       190\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import gym_anytrading\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3 import DQN\n",
        "\n",
        "# Load Historical Stock Data\n",
        "df['Date'] = pd.to_datetime(df.index)\n",
        "df.set_index('Date', inplace=True)\n",
        "\n",
        "# Define the Trading Environment\n",
        "class CustomTradingEnv(gym.Env):\n",
        "    def __init__(self, df, window_size=10):\n",
        "        super(CustomTradingEnv, self).__init__()\n",
        "\n",
        "        self.df = df\n",
        "        self.window_size = window_size\n",
        "        self.current_step = window_size\n",
        "\n",
        "        # Define Action Space (Buy, Hold, Sell)\n",
        "        self.action_space = gym.spaces.Discrete(3)\n",
        "\n",
        "        # Define State Space (All Features)\n",
        "        self.observation_space = gym.spaces.Box(\n",
        "            low=-np.inf, high=np.inf, shape=(window_size, len(df.columns)), dtype=np.float32\n",
        "        )\n",
        "\n",
        "        # Track balance, shares, and profit\n",
        "        self.balance = 10000  # Starting capital\n",
        "        self.shares_held = 0\n",
        "        self.total_profit = 0\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_step = self.window_size\n",
        "        self.balance = 10000\n",
        "        self.shares_held = 0\n",
        "        self.total_profit = 0\n",
        "        return self._get_observation()\n",
        "\n",
        "    def step(self, action):\n",
        "        current_price = self.df.iloc[self.current_step]['Close']\n",
        "\n",
        "        # Execute Trade\n",
        "        if action == 0:  # Sell\n",
        "            self.balance += self.shares_held * current_price\n",
        "            self.shares_held = 0\n",
        "        elif action == 2:  # Buy\n",
        "            num_shares = self.balance // current_price\n",
        "            self.balance -= num_shares * current_price\n",
        "            self.shares_held += num_shares\n",
        "\n",
        "        # Calculate Reward (Profit)\n",
        "        self.total_profit = self.balance + (self.shares_held * current_price) - 10000\n",
        "        reward = self.total_profit\n",
        "\n",
        "        # Move to the Next Step\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= len(self.df) - 1\n",
        "\n",
        "        return self._get_observation(), reward, done, {}\n",
        "\n",
        "    def _get_observation(self):\n",
        "        return self.df.iloc[self.current_step - self.window_size : self.current_step].values\n",
        "\n",
        "# Create Environment\n",
        "env = CustomTradingEnv(df)\n"
      ],
      "metadata": {
        "id": "NcNWnAZPUoTJ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the DQN Model\n",
        "model = DQN(\"MlpPolicy\", env, verbose=1, learning_rate=0.001, batch_size=32, buffer_size=5000, exploration_fraction=0.1)\n",
        "\n",
        "# Train the Model\n",
        "model.learn(total_timesteps=10000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34f-JLUhUufg",
        "outputId": "a173e3bb-abf4-42ed-ca4c-9518ee3febb6"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/monitor.py:95: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  self.rewards.append(float(reward))\n",
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:59: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 946      |\n",
            "|    ep_rew_mean      | 3.13e+06 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 296      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 3784     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 1.62e+05 |\n",
            "|    n_updates        | 920      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 946      |\n",
            "|    ep_rew_mean      | 3.82e+06 |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 328      |\n",
            "|    time_elapsed     | 23       |\n",
            "|    total_timesteps  | 7568     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 1.25e+05 |\n",
            "|    n_updates        | 1866     |\n",
            "----------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.dqn.dqn.DQN at 0x785f1f8fe350>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset Environment\n",
        "obs = env.reset()\n",
        "done = False\n",
        "profits = []\n",
        "\n",
        "while not done:\n",
        "    action, _ = model.predict(obs)  # Select Best Action\n",
        "    obs, reward, done, _ = env.step(action)\n",
        "    profits.append(env.total_profit)\n",
        "\n",
        "# Plot Trading Performance\n",
        "plt.plot(profits)\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Total Profit ($)\")\n",
        "plt.title(\"Reinforcement Learning Trading Performance\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "LtCfeDBCVPlD",
        "outputId": "8f21c053-9f6b-4922-851d-d6bd2b92bf15"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}